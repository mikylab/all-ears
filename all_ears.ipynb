{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "028c42ed-471a-45a3-8252-e81020a1ff28",
   "metadata": {},
   "source": [
    "# All Ears - CS 545 Final Project & Report\n",
    "\n",
    "Mikyla Bowen and Nathan Orwick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832423ec-4dc5-4a22-8a55-f7b490d9c69c",
   "metadata": {},
   "source": [
    "## Introduction & methodology\n",
    "\n",
    "Good description of the data and methodology (20 pts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e88ab5-8e83-413b-bb87-ea5c893c140e",
   "metadata": {},
   "source": [
    "## Experiments & analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8256e381-1c75-44ab-a2c6-9ebf0d340971",
   "metadata": {},
   "source": [
    "### Shared imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27dbb7-8425-441b-a9cb-ce3069e55b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import shared_loader\n",
    "import shared_models\n",
    "import shared_utils\n",
    "from shared_utils import device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45dbfd6-035e-430b-a417-1873a30eda96",
   "metadata": {},
   "source": [
    "### Basic ear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e70a90-4e28-44cc-b604-90de4aec476e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c7fa1d-1925-4ddb-a052-d4162c1d5bb4",
   "metadata": {},
   "source": [
    "### Paired ear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c946a76-39cd-4955-a330-d414b8fd917d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = shared_loader.PairedEarData(batch_size=128)\n",
    "batch = next(iter(data.get_dataloader(train=True)))\n",
    "data.visualize(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73d26f-cf7d-4e59-9c83-f672c02228a3",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7fbcb-7e42-4fb4-bce8-49a92ddb7ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = shared_models.PairCNN()\n",
    "model.apply(shared_utils.init_cnn)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a005a484-be48-472e-b3aa-52765be53a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_train, loss_valid, accuracy_valid = shared_utils.bc_model_training(\n",
    "    model, data, optimizer, loss_fn, epochs=10, early_stopping=False, verbose=True\n",
    ")\n",
    "print(f\"accuracy: {accuracy_valid[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc03cbe-c4b8-4922-973e-f3d1affc897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(range(1, len(loss_train)+1), loss_train, label='training loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), loss_valid, label='validation loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), accuracy_valid, label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64d340-2dfc-45d3-ac58-84d08806a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.bc_confusion_matrix(data, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f987eef8-65d5-4f8b-b67d-5daa6b5281a8",
   "metadata": {},
   "source": [
    "#### ResNet18 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f4c60-7cc8-43b7-9200-cff6d54d2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = shared_models.PairResnet18(pretrained=False)\n",
    "\n",
    "model.fc.apply(shared_utils.init_cnn)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a5d5f-cd2e-451a-ac44-44bfe5059ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_train, loss_valid, accuracy_valid = shared_utils.bc_model_training(\n",
    "    model, data, optimizer, loss_fn, epochs=10, early_stopping=False, verbose=True\n",
    ")\n",
    "print(f\"accuracy: {accuracy_valid[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedcaf0-6d1e-47d7-a246-b8cd5ad31684",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(range(1, len(loss_train)+1), loss_train, label='training loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), loss_valid, label='validation loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), accuracy_valid, label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d9acc-271e-41ed-9e8c-dcb96542b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.bc_confusion_matrix(data, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98498580-d3fe-498b-982a-ccc677eef69c",
   "metadata": {},
   "source": [
    "#### Pretrained ResNet18 fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0bf005-14ab-4f97-8599-ad7cbf4b119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = shared_models.PairResnet18()\n",
    "\n",
    "model.fc.apply(shared_utils.init_cnn)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "learning_rate = 0.0001\n",
    "params_1x = model.resnet.parameters()\n",
    "params_fc = model.fc.parameters()\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': params_1x}, {'params': params_fc, 'lr': learning_rate * 10}],\n",
    "    lr=learning_rate, weight_decay=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf748c-1dd3-4057-b4f2-6bdc74782dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_train, loss_valid, accuracy_valid = shared_utils.bc_model_training(\n",
    "    model, data, optimizer, loss_fn, epochs=3, early_stopping=False, verbose=True\n",
    ")\n",
    "print(f\"accuracy: {accuracy_valid[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c92af7-4843-4e71-9513-b138cae11289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(range(1, len(loss_train)+1), loss_train, label='training loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), loss_valid, label='validation loss')\n",
    "plt.plot(range(1, len(loss_valid)+1), accuracy_valid, label='validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073f053-10d8-46bb-bd93-f540555526e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.bc_confusion_matrix(data, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e73d71-b1c4-44e0-b895-d09287eb32f9",
   "metadata": {},
   "source": [
    "#### Paired ear classification discussion\n",
    "\n",
    "Will finish in the word doc to be dropped here later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16adaf3-d225-4e31-9a7b-918792f2d992",
   "metadata": {},
   "source": [
    "### Gender classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8319f4e-b563-4d77-9734-5c2dd8383ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8b9c966-cbbb-4415-942f-bac4d55e9d3a",
   "metadata": {},
   "source": [
    "## Team member contribution\n",
    "\n",
    "At the end of the notebook, describe team member contributions.\n",
    "\n",
    "We could probably just make the word doc table a markdown table, maybe this will work: https://tableconvert.com/excel-to-markdown"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
